---
title: "knn"
author: "Juan Luis Suárez Díaz"
date: "10 de febrero de 2019"
output: pdf_document
---

```{r}
train <- read.csv("train.csv", na.strings = c("?", "NA", "NR", "na", "NaN", "nan"))
train$C <- as.factor(train$C)
test <- read.csv("test.csv", na.strings = c("?", "NA", "NR", "na", "NaN", "nan"))
sample <- read.csv("sampleSubmission.csv")

## BIBLIOTECAS

library(ggplot2)
library(caret)
library(RKEEL)
# library(rDML) # Por si acaso
library(kknn)
library(GGally)
library(Hmisc)
library(dplyr)
library(corrplot)
library(tidyr)
library(VIM)
library(mice)
library(bmrm)
library(DMwR)
library(NoiseFiltersR)
library(beeswarm)
library(moments)
library(MASS)
library(FSelector)
```

```{r}
## ANÁLISIS

# Resumen de los datos
summary(train)
summary(test)
```

```{r}
describe(train)
describe(test)
```

```{r}
# Primera cosa rara: hay datos basura con -68000 y pico en todas sus variables.

train[apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)),]

# Son todo números casi iguales y tienen clases distintas. Quizás es mejor eliminarlos todos. Problema: también hay datos de este tipo en test
```

```{r}
test[apply(test, MARGIN=1, function(x) any(!is.na(x) & x < -68000)),]
# A estas mierdas hay que asignarles la clase de alguna forma.
```

```{r}
ggplot(train[apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)),], aes(x=C, fill=C)) + geom_histogram(stat="count")
# En train hay bastantes más ceros, tal vez lo mejor sea asignar todas las test a 0.
```

```{r}
# Índices de estos outliers por si hay que quitarlos
outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
```

```{r}
# Valores perdidos
has.na <- function(x) apply(x,1,function(z)any(is.na(z)))
train[has.na(train),] # 1366 ejemplos con na en train
test[has.na(test),] # No hay NAs en test
# Me suena que dijo salva que test estaba limpio, no solo de nas, sino de ruido también
```

```{r}
# NAs por variable
apply(train, 2, function(x) sum(is.na(x)))
```

```{r}
# NAs por ejemplo
hist(apply(train, 1, function(x) sum(is.na(x))))
# LOL? solo hay un NA por ejemplo oks
# Aunque esto es genial para imputar NAs usando clasificadores (regresores más bien).
```

```{r}
indices.nas.train <- which(has.na(train))
```


```{r}
# Distribución de clases
ggplot(train, aes(x=C, fill=C)) + geom_histogram(stat="count")

train %>%
  group_by(C) %>%
  summarize(n = n())

# En torno a 6000 datos de clase positiva y 3000 de clase negativa :(
```

```{r}
# Correlaciones
corrplot(cor(train[-c(indices.nas.train),-ncol(train)]))
# Muy sospechoso, a ver si quitando los outliers mierda esos
```

```{r}
corrplot(cor(train[-c(indices.nas.train, outliers.train.por.la.cara),-ncol(train)]))
# Esto ya pinta mejor
```

```{r}
# Variables más correladas
cor(train[-c(indices.nas.train, outliers.train.por.la.cara),-ncol(train)]) %>%
  as.data.frame() %>%
  mutate(var1 = rownames(.)) %>%
  gather(var2, value, -var1) %>%
  arrange(desc(value)) %>%
  filter(var1 < var2)
```

```{r}
corrplot(cor(train[-c(indices.nas.train, outliers.train.por.la.cara),c(16,17,33,38,23,15,40,46,31,21,26)]))

```

```{r}
ggplot(train[-outliers.train.por.la.cara,], aes(x=X16, y=X17, col=C)) + geom_point()
# Clarísima la dependencia. Podríamos elegir la que parezca tener menos ruido para clasificar
```

```{r}
ggplot(train[-outliers.train.por.la.cara,], aes(x=X33, y=X38, col=C)) + geom_point()
# No hay correlación lineal pero ahí está pasando claramente algo.
```

```{r}
ggplot(train[-outliers.train.por.la.cara,], aes(x=X16, y=X23, col=C)) + geom_point()
# Ya empieza a verse menos claro
```

```{r}
ggplot(train[-outliers.train.por.la.cara,], aes(x=X15, y=X16, col=C)) + geom_point()
```

```{r}
ggplot(train[-outliers.train.por.la.cara,], aes(x=X17, y=X23, col=C)) + geom_point()
```

```{r}
# Por curiosidad, qué pasará en test?
ggplot(test[-outliers.test.por.la.cara,], aes(x=X16, y=X17)) + geom_point()
ggplot(test[-outliers.test.por.la.cara,], aes(x=X33, y=X38)) + geom_point()
ggplot(test[-outliers.test.por.la.cara,], aes(x=X16, y=X23)) + geom_point()
ggplot(test[-outliers.test.por.la.cara,], aes(x=X15, y=X16)) + geom_point()
ggplot(test[-outliers.test.por.la.cara,], aes(x=X17, y=X23)) + geom_point()
# Bastante parecidos
```

```{r}
# Componentes principales
pca.bruto <- prcomp(train[-c(outliers.train.por.la.cara, indices.nas.train),-ncol(train)], center=T, scale=T)
plot(pca.bruto)
summary(pca.bruto)
# 95 % -> 30 PCs
# 90 % -> 23 PCs
# 85 % -> 18 PCs
# 80 % -> 14 PCs
```

```{r}
# Se verá algo con 2 PCAs?
pca.plano <- cbind(as.data.frame(predict(pca.bruto)[,1:2]), C = train$C[-c(outliers.train.por.la.cara, indices.nas.train)])
ggplot(pca.plano, aes(x=PC1, y=PC2, col=C)) + geom_point()
# Pues no
```

```{r}
# Funcionará aprender distancias?
# library(rDML)
# scaled.train <- as.data.frame(scale(train[,-ncol(train)]))
# dmlmj <- dml$DMLMJ()
# dmlmj$fit(scaled.train[-c(outliers.train.por.la.cara, indices.nas.train),], train[-c(outliers.train.por.la.cara, indices.nas.train),ncol(train)])
# dmlmj$metric()
# dmlmj$transformer()
# Funciona (por lo menos en mi ordenador), aunque demasiado lento, y este es de los rápidos :(
```

```{r}
# Diferencias entre densidades para cada variable (train / test)
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X1)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X1)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X2)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X2)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X3)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X3)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X4)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X4)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X5)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X5)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X6)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X6)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X7)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X7)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X8)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X8)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X9)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X9)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X10)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X10)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X11)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X11)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X12)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X12)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X13)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X13)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X14)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X14)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X15)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X15)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X16)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X16)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X17)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X17)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X18)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X18)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X19)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X19)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X20)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X20)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X21)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X21)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X22)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X22)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X23)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X23)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X24)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X24)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X25)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X25)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X26)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X26)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X27)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X27)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X28)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X28)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X29)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X29)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X30)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X30)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X31)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X31)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X32)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X32)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X33)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X33)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X34)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X34)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X35)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X35)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X36)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X36)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X37)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X37)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X38)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X38)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X39)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X39)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X40)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X40)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X41)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X41)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X42)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X42)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X43)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X43)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X44)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X44)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X45)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X45)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X46)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X46)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X47)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X47)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X48)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X48)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X49)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X49)) + geom_density()
  
  ggplot(train[-outliers.train.por.la.cara,], aes(x=X50)) + geom_density()
  ggplot(test[-outliers.test.por.la.cara,], aes(x=X50)) + geom_density()
  

```
```{r}
# X6 toma negativos en train pero no en test -> o negativos pasan a ser 0 o se eliminan
# Posible outlier en X7 (X7 > 300)
# X45
```

```{r}
# No había caído antes, pero aunque los outliers no afectan directamente al knn (los vecinos cercanos no van a ser outliers),
# si afecta mucho a la normalización, por lo que hay que quitarlos. Para el z-score deberían afectar solo los univariantes
vector_claves_outliers_IQR_en_alguna_columna <-  function(datos, coef = 1.5){
  return(unique(unlist(sapply(1:ncol(datos),vector_claves_outliers_IQR, 
                       datos=datos, coef=coef))))
}

length(vector_claves_outliers_IQR_en_alguna_columna(train[-c(outliers.train.por.la.cara, indices.nas.train),-ncol(train)], coef=1.5))
length(vector_claves_outliers_IQR_en_alguna_columna(train[-c(outliers.train.por.la.cara, indices.nas.train),-ncol(train)], coef=3.0))
# 4000 normales y 2000 extremos, parecen demasiados
```

```{r}
length(vector_claves_outliers_IQR_en_alguna_columna(test[-c(outliers.test.por.la.cara),], coef=1.5))
length(vector_claves_outliers_IQR_en_alguna_columna(test[-c(outliers.test.por.la.cara),], coef=3.0))

```

```{r}
for(i in 1:50){
  boxplot(cbind(train[-c(outliers.train.por.la.cara),i], test[-c(outliers.test.por.la.cara),i]))
}
```

```{r}
# Simetría y curtosis (diferencia entre centro y extremos respecto a la normal.)
skewness(train[-c(outliers.train.por.la.cara, indices.nas.train),-ncol(train)])
kurtosis(train[-c(outliers.train.por.la.cara, indices.nas.train),-ncol(train)])-3

skewness(test[-c(outliers.test.por.la.cara),-ncol(test)])
kurtosis(test[-c(outliers.test.por.la.cara),-ncol(test)])-3
# Hay variables demasiado asimétricas y eso puede estorbar mucho en la normalización por z-score
```

```{r}
symmetrize.log <- function(data, skew.thres = 1.5, kurt.thres = 1.5){
  data.sym <- data.frame(data)
  for(i in 1:50){
      kurt <- kurtosis(data[,i]) - 3
      skew <- skewness(data[,i])
      if(abs(kurt) > kurt.thres || abs(skew) > skew.thres){
        col.min <- min(data[,i])
        if(col.min <= 0){
          data.sym[,i] <- log(data[,i] + 0.1 - col.min) 
        }
        else{
          data.sym[,i] <- log(data[,i])
        }
      }
  }
  data.sym
}

symmetrize.boxcox <- function(data, skew.thres = 1.5, kurt.thres = 1.5){
  data.sym <- data.frame(data)
  boxcoxs <- list()
  col.mins <- c()
  for(i in 1:50){
      kurt <- kurtosis(data[,i]) - 3
      skew <- skewness(data[,i])
      if(abs(kurt) > kurt.thres || abs(skew) > skew.thres){
        col.mins <- c(col.mins, min(data[,i]))
        if(col.mins[i] <= 0){
          boxcoxs[[i]] <- BoxCoxTrans(data[,i] + 25000 - col.mins[i])
          data.sym[,i] <- predict(boxcoxs[[i]], data[,i] + 1 - col.mins[i])
        }
        else{
          boxcoxs[[i]] <- BoxCoxTrans(data[,i])
          data.sym[,i] <- predict(boxcoxs[[i]], 25000 + data[,i])
        }
      }
      else{
        boxcoxs[[i]] <- 0
        col.mins <- c(col.mins, 0)
      }
  }
  return(list(models=boxcoxs, mins = col.mins, data.sym = data.sym))
}

symmetrize.boxcox.predict <- function(data, models, col.mins){
  data.sym <- data.frame(data)
  for(i in 1:50){
    if(!is.numeric(models[[i]])){
      if(col.mins[i] <= 0){
        data.sym[,i] <- predict(models[[i]], data[,i] + 25000 - col.mins[i])
      }
      else{
        data.sym[,i] <- predict(models[[i]], data[,i] + 25000)
      }
    }
  }
  data.sym
}

train.sym.model <- symmetrize.boxcox(train[-c(outliers.train.por.la.cara, indices.nas.train),])
train.sym <- symmetrize.boxcox.predict(train[-c(outliers.train.por.la.cara, indices.nas.train),], train.sym.model$models, train.sym.model$mins)
skewness(train.sym[,-ncol(train)])
kurtosis(train.sym[,-ncol(train)])-3
# El logaritmo no simetriza del todo bien algunas variables (de hecho, algunas las empeora)
# La BoxCox lo hace mucho mejor, aunque no es perfecta

# Outliers posibles tras simetrizar en X5, X7, X9, ¿X10?, X11,  X23, X29, ¿X34?, X35, x36, X37, X40, ¿X41?, X43, X48, X49
# X45 y X47 siguen siendo raras
```

```{r}
johnson <- preProcess(train[-c(outliers.train.por.la.cara, indices.nas.train),], method="YeoJohnson")
train.sym <- predict(johnson, train[-c(outliers.train.por.la.cara, indices.nas.train),])
skewness(train.sym[,-ncol(train)])
kurtosis(train.sym[,-ncol(train)])-3
```

```{r}
#################################################################################################################
#################################################################################################################
#################################################################################################################
#################################################################################################################
```

```{r}
createSubmission <- function(pred, filename){
  sub <- cbind(Id = 1:length(pred), Prediction = as.numeric(as.character(pred)))
  write.csv(sub, paste0("subs-knn/",filename), row.names = F)
  sub
}
```

```{r}
library(bmrm)

# Calcula el score de validación cruzada para el dataset
# funcion.train.predict: función(train, test) que entrena el clasificador con train y devuelve las predicciones sobre test
cross_validation <- function(dataset, funcion.train.predict, folds = 10){
  fold.indexes <- balanced.cv.fold(dataset$C)
  return(mean(sapply(1:folds, cross_validation_fold, fold.indexes, dataset, funcion.train.predict)))
}

cross_validation_fold <- function(fold, indexes, dataset, funcion.train.predict){
  train.inds <- which(indexes==fold)
  train <- dataset[train.inds,]
  test <- na.omit(dataset[-train.inds,])
  ypred <- funcion.train.predict(train, test[,-ncol(test)])
  mean(ypred==test$C)
}
```

```{r}
# Probando validación cruzada
set.seed(28)
funcion.train.predict <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  indices.nas.train <- which(has.na(train))
  knn.model <- train(C ~ ., train[-c(outliers.train.por.la.cara, indices.nas.train),], method="knn", preProcess = c("center", "scale"))
  
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, funcion.train.predict)
```


```{r}
set.seed(28)
train.predict.nas.por.media <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  # Imputación de NAs por defecto Mice
  imputados <- mice::mice(train, m=1, method="mean")
  train.completed <- mice::complete(imputados)
  knn.model <- train(C ~ ., train.completed, method="knn", preProcess = c("center", "scale"))
  
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.nas.por.media)
```

```{r}
# Imputación con knn
set.seed(28)
train.predict.knn.imputation <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  knn.model <- train(C ~ ., train.completed, method="knn", preProcess = c("center", "scale"), tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
  print(knn.model)
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.knn.imputation)
```

```{r}
# Imputación con knn por clases
set.seed(28)
train.predict.knn.imputation.by.class <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed.0 <- knnImputation(train[train$C == 0,]) 
  train.completed.1 <- knnImputation(train[train$C == 1,])
  train.completed <- rbind(train.completed.0, train.completed.1)
  knn.model <- train(C ~ ., train.completed, method="knn", preProcess = c("center", "scale"), tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
  print(knn.model)
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.knn.imputation.by.class)
```

```{r}
# PCAs
set.seed(28)
train.predict.pca <- function(train, test, ncomps){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train)
  pca <- prcomp(train.completed[,-ncol(train.completed)], center=T, scale=T)
  train.pca <- as.data.frame(predict(pca, train.completed)[,1:ncomps])
  knn.model <- train(C ~ ., cbind(train.pca,C = train.completed$C), method="knn", tuneGrid = expand.grid(k=c(15)))
  print(knn.model)
  # Predict
  test.pca <- as.data.frame(predict(pca, test)[, 1:ncomps])
  preds <- predict(knn.model, test.pca)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

# cross_validation(train, function(train, test) train.predict.pca(train, test, 50))
pca.scores <- sapply(2:50, function(i) cross_validation(train, function(tr, ts) train.predict.pca(tr, ts, i)))
```

```{r}
# Imputación con knn por clases, probando k=1 (Salva dice que debe ir mejor, aunque la CV dice lo contrario)
set.seed(28)
train.predict.knn.imputation.k.1 <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  knn.model <- train(C ~ ., train.completed, method="knn", preProcess = c("center", "scale"), tuneGrid = expand.grid(k=c(1)),
                     trControl = trainControl(method="none"))
  print(knn.model)
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.knn.imputation.k.1)
```

```{r}
set.seed(28)
train.predict.knn.imputation.mas.precisa <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- data.frame(train)
  nas.ordenados <- order(apply(train, 2, function(x) sum(is.na(x))), decreasing = T)[-51]
  
  # Imputación knn encadenada
  for(i in 1:50){
    indices.nas.train <- which(has.na(train.completed))
    print(length(indices.nas.train))
    na.labels.train <- train.completed[-indices.nas.train,nas.ordenados[i]]
    na.data.train <- train.completed[-indices.nas.train, -c(nas.ordenados[i], 50)]
    na.data.test <- train.completed[which(is.na(train[,nas.ordenados[i]])), -c(nas.ordenados[i], 50)]
    knn.na.model <- train(na.data.train, na.labels.train, 
                          method="knn", preProcess=c("center", "scale"), tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
    na.labels.test <- predict(knn.na.model, na.data.test)
    train.completed[which(is.na(train[,nas.ordenados[i]])), nas.ordenados[i]] <- na.labels.test
  }
  knn.model <- train(C ~ ., train.completed, method="knn", preProcess = c("center", "scale"), tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
  print(knn.model)
  
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

  cross_validation(train, train.predict.knn.imputation.mas.precisa)
```

```{r}
# Imputación con knn + EF por consenso
set.seed(28)
train.predict.knn.imputation.ef <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  train.cleaned <- EF(train.completed)$cleanData
  knn.model <- train(C ~ ., train.cleaned, method="knn", preProcess = c("center", "scale"), tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
  print(knn.model)
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.knn.imputation.ef)
```

```{r}
# Imputación con knn + EF por mayoria
set.seed(28)
train.predict.knn.imputation.ef.majority <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  train.cleaned <- EF(train.completed, consensus = F)$cleanData
  knn.model <- train(C ~ ., train.cleaned, method="knn", preProcess = c("center", "scale"), tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
  print(knn.model)
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.knn.imputation.ef.majority)
```

```{r}
# Imputación con knn + CVCF por consenso
set.seed(28)
train.predict.knn.imputation.cvcf <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  train.cleaned <- CVCF(train.completed, consensus = T)$cleanData
  knn.model <- train(C ~ ., train.cleaned, method="knn", preProcess = c("center", "scale"), tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
  print(knn.model)
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.knn.imputation.cvcf)
```

```{r}
# Imputación con knn + CVCF por mayoría
set.seed(28)
train.predict.knn.imputation.cvcf.majority <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  train.cleaned <- CVCF(train.completed, consensus = F)$cleanData
  knn.model <- train(C ~ ., train.cleaned, method="knn", preProcess = c("center", "scale"), tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
  print(knn.model)
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.knn.imputation.cvcf.majority)
```

```{r}
# Imputación con knn + IPF por consenso
set.seed(28)
train.predict.knn.imputation.ipf <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  train.cleaned <- IPF(train.completed, consensus = T)$cleanData
  knn.model <- train(C ~ ., train.cleaned, method="knn", preProcess = c("center", "scale"), tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
  print(knn.model)
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.knn.imputation.ipf)
```

```{r}
# Imputación con knn + IPF por mayoría
set.seed(28)
train.predict.knn.imputation.ipf.majority <- function(train, test){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) && x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  train.cleaned <- IPF(train.completed, consensus = F)$cleanData
  knn.model <- train(C ~ ., train.cleaned, method="knn", preProcess = c("center", "scale"), tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
  print(knn.model)
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.knn.imputation.ipf.majority)
```


```{r}
# Imputación con knn y mejor filtro de ruido + simetrización
set.seed(28)
train.predict.14 <- function(train, test){
  # Train
  # Fuera outliers por la cara
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  # Imputación knn
  train.completed <- knnImputation(train) 
  # Filtro de ruido
  train.cleaned <- CVCF(train.completed, consensus = F)$cleanData
  # Train
  knn.model <- train(C ~ ., train.cleaned, method="knn", preProcess = c("YeoJohnson", "center", "scale"), 
                      tuneGrid = expand.grid(k=c(1,3,5,7,9,11,13,15)))
  print(knn.model)
  # Predict
  preds <- predict(knn.model, test)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

cross_validation(train, train.predict.14)
```

```{r}
# 11 + tuneado mas fuerte
set.seed(28)
train.predict.15 <- function(train, test, k, kernel){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  train.cleaned <- CVCF(train.completed, consensus = F)$cleanData
  scaler <- preProcess(train.cleaned) # Centrado y escalado
  train.scaled <- predict(scaler, train.cleaned)
  knn.model <- train.kknn(C ~ ., train.scaled, ks = k, kernel = kernel, scale=F)
  # Predict
  test.scaled <- predict(scaler, test)
  preds <- predict(knn.model, test.scaled)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

train.predict.15.with.cleaned.data <- function(train, test, k, kernel){
  scaler <- preProcess(train) # Centrado y escalado
  train.scaled <- predict(scaler, train)
  knn.model <- train.kknn(C ~ ., train.scaled, ks = k, kernel = kernel, scale=F)
  test.scaled <- predict(scaler, test)
  preds <- predict(knn.model, test.scaled)
  return(preds)
}

ks <- c(11,13,15,17,19,21,23)
kernels <- c("rectangular", "triangular", "epanechnikov", "biweight", "triweight", "cos", "inv", "gaussian", "optimal")
cv.all <- data.frame()
cv.cleaned <- data.frame()
for(k in ks){
  for(kernel in kernels){
    tp <- function(tr, tst) train.predict.15(tr, tst, k, kernel)
    print(paste0("K = ", k, "; KERNEL = ", kernel))
    cv.i <- cross_validation(train, tp)
    print(cv.i)
    cv.all[as.character(k), kernel] <- cv.i
  }
}

train.revised <- train[-outliers.train.por.la.cara,]
train.completed <- knnImputation(train.revised)
train.cleaned <- CVCF(train.completed, consensus=F)$cleanData
for(k in ks){
  for(kernel in kernels){
    tp <- function(tr, tst) train.predict.15.with.cleaned.data(tr, tst, k, kernel)
    print(paste0("K = ", k, "; KERNEL = ", kernel))
    cv.i <- cross_validation(train.cleaned, tp)
    print(cv.i)
    cv.cleaned[as.character(k), kernel] <- cv.i
  }
}

```

```{r}
# Lo anterior añadiendo selección de características (RELIEF)
set.seed(28)
train.predict.18 <- function(train, test, k, kernel){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  train.cleaned <- CVCF(train.completed, consensus = F)$cleanData
  scaler <- preProcess(train.cleaned) # Centrado y escalado
  train.scaled <- predict(scaler, train.cleaned)
  # Pesos relief
  relief.weights <- relief(C ~ ., train.scaled, neighbours.count = 17)$attr_importance
  barplot(relief.weights)
  relief.weights[relief.weights < 0] <- 0
  relief.weights <- sqrt(relief.weights) # Para que funcionen como pesos con la distancia euclidea.
  train.weighted <- data.frame(t(relief.weights * t(train.scaled[,-ncol(train.scaled)])), C = train.scaled$C)
  train.weighted <- train.weighted[, colSums(train.weighted != 0) > 0]
  
  # Train
  knn.model <- train.kknn(C ~ ., train.weighted, ks = k, kernel = kernel, scale=F)
  # Predict
  # Centrado y escalado
  test.scaled <- predict(scaler, test)
  # Pesos relief
  test.weighted <- data.frame(t(relief.weights * t(test.scaled)))
  test.weighted <- test.weighted[, colSums(test.weighted != 0) > 0]
  preds <- predict(knn.model, test.weighted)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

train.predict.18.with.cleaned.data <- function(train, test, k, kernel){
  scaler <- preProcess(train) # Centrado y escalado
  train.scaled <- predict(scaler, train)
  # Pesos relief
  relief.weights <- relief(C ~ ., train.scaled, neighbours.count = 17)$attr_importance
  relief.weights[relief.weights < 0] <- 0
  relief.weights <- sqrt(relief.weights) # Para que funcionen como pesos con la distancia euclidea.
  train.weighted <- data.frame(t(relief.weights * t(train.scaled[,-ncol(train.scaled)])), C = train.scaled$C)
  train.weighted <- train.weighted[, colSums(train.weighted != 0) > 0]
  # Train
  knn.model <- train.kknn(C ~ ., train.weighted, ks = k, kernel = kernel, scale=F)
  #Predict
  test.scaled <- predict(scaler, test)
  # Pesos relief
  test.weighted <- data.frame(t(relief.weights * t(test.scaled)))
  test.weighted <- test.weighted[, colSums(test.weighted != 0) > 0]
  preds <- predict(knn.model, test.weighted)
  return(preds)
}

ks <- c(15,17,19)
kernels <- c("rectangular", "triangular", "epanechnikov", "biweight", "triweight", "cos", "inv", "gaussian", "optimal")
cv.all <- data.frame()
cv.cleaned <- data.frame()
for(k in ks){
  for(kernel in kernels){
    tp <- function(tr, tst) train.predict.18(tr, tst, k, kernel)
    print(paste0("K = ", k, "; KERNEL = ", kernel))
    cv.i <- cross_validation(train, tp)
    print(cv.i)
    cv.all[as.character(k), kernel] <- cv.i
  }
}

train.revised <- train[-outliers.train.por.la.cara,]
train.completed <- knnImputation(train.revised)
train.cleaned <- CVCF(train.completed, consensus=F)$cleanData
for(k in ks){
  for(kernel in kernels){
    tp <- function(tr, tst) train.predict.18.with.cleaned.data(tr, tst, k, kernel)
    print(paste0("K = ", k, "; KERNEL = ", kernel))
    cv.i <- cross_validation(train.cleaned, tp)
    print(cv.i)
    cv.cleaned[as.character(k), kernel] <- cv.i
  }
}

```

```{r}
# 16 + tuneado PCA
set.seed(28)
train.predict.21 <- function(train, test, k, kernel, ndims){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  train.cleaned <- CVCF(train.completed, consensus = F)$cleanData
  scaler <- preProcess(train.cleaned, method=c("center", "scale", "pca"), pcaComp=ndims) # escalado + PCA
  train.scaled <- predict(scaler, train.cleaned)
  knn.model <- train.kknn(C ~ ., train.scaled, ks = k, kernel = kernel, scale=F)
  # Predict
  test.scaled <- predict(scaler, test)
  preds <- predict(knn.model, test.scaled)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

train.predict.21.with.cleaned.data <- function(train, test, k, kernel, ndims){
  scaler <- preProcess(train, method=c("center", "scale", "pca"), pcaComp = ndims) # Centrado y escalado
  train.scaled <- predict(scaler, train)
  knn.model <- train.kknn(C ~ ., train.scaled, ks = k, kernel = kernel, scale=F)
  test.scaled <- predict(scaler, test)
  preds <- predict(knn.model, test.scaled)
  return(preds)
}

# ks <- c(11,13,15,17,19,21,23)
kernels <- c("rectangular", "triangular", "epanechnikov", "cos", "inv", "gaussian", "optimal")
dims <- c(10, 20, 25, 30, 32, 34, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49)
cv.all <- data.frame()
cv.cleaned <- data.frame()
for(dim in dims){
  for(kernel in kernels){
    tp <- function(tr, tst) train.predict.21(tr, tst, 17, kernel, dim)
    print(paste0("DIM = ", dim, "; KERNEL = ", kernel))
    cv.i <- cross_validation(train, tp)
    print(cv.i)
    cv.all[as.character(dim), kernel] <- cv.i
  }
}

train.revised <- train[-outliers.train.por.la.cara,]
train.completed <- knnImputation(train.revised)
train.cleaned <- CVCF(train.completed, consensus=F)$cleanData
for(dim in dims){
  for(kernel in kernels){
    tp <- function(tr, tst) train.predict.21.with.cleaned.data(tr, tst, 17, kernel, dim)
    print(paste0("DIM = ", dim, "; KERNEL = ", kernel))
    cv.i <- cross_validation(train.cleaned, tp)
    print(cv.i)
    cv.cleaned[as.character(dim), kernel] <- cv.i
  }
}

```


```{r}
# 16 + tuneado PCA threshold
set.seed(28)
train.predict.22 <- function(train, test, k, kernel, thresh){
  # Train
  outliers.train.por.la.cara <- which(apply(train[,-ncol(train)], MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  outliers.test.por.la.cara <- which(apply(test, MARGIN=1, function(x) any(!is.na(x) & x < -68000)))
  if(length(outliers.train.por.la.cara) > 0) train <- train[-outliers.train.por.la.cara,]
  train.completed <- knnImputation(train) 
  train.cleaned <- CVCF(train.completed, consensus = F)$cleanData
  scaler <- preProcess(train.cleaned, method=c("center", "scale", "pca"), thresh=thresh) # escalado + PCA
  train.scaled <- predict(scaler, train.cleaned)
  knn.model <- train.kknn(C ~ ., train.scaled, ks = k, kernel = kernel, scale=F)
  # Predict
  test.scaled <- predict(scaler, test)
  preds <- predict(knn.model, test.scaled)
  preds[outliers.test.por.la.cara] <- 0
  return(preds)
}

train.predict.22.with.cleaned.data <- function(train, test, k, kernel, thresh){
  scaler <- preProcess(train, method=c("center", "scale", "pca"), thresh=thresh) # Centrado y escalado
  train.scaled <- predict(scaler, train)
  knn.model <- train.kknn(C ~ ., train.scaled, ks = k, kernel = kernel, scale=F)
  test.scaled <- predict(scaler, test)
  preds <- predict(knn.model, test.scaled)
  return(preds)
}

# ks <- c(11,13,15,17,19,21,23)
kernels <- c("rectangular", "triangular", "epanechnikov", "cos", "inv", "gaussian", "optimal")
cv.all <- data.frame()
cv.cleaned <- data.frame()
for(kernel in kernels){
    tp <- function(tr, tst) train.predict.22(tr, tst, 17, kernel, 0.99)
    print(paste0("KERNEL = ", kernel))
    cv.i <- cross_validation(train, tp)
    print(cv.i)
    # cv.all[as.character(dim), kernel] <- cv.i
}

train.revised <- train[-outliers.train.por.la.cara,]
train.completed <- knnImputation(train.revised)
train.cleaned <- CVCF(train.completed, consensus=F)$cleanData
for(kernel in kernels){
    tp <- function(tr, tst) train.predict.22.with.cleaned.data(tr, tst, 17, kernel, 0.99)
    print(paste0("KERNEL = ", kernel))
    cv.i <- cross_validation(train.cleaned, tp)
    print(cv.i)
    # cv.cleaned[as.character(dim), kernel] <- cv.i
  
}
```


```{r}
#########################################################################################################################3
```

```{r}
## SUBIDA 1

set.seed(28)
sub.prueba <- funcion.train.predict(train, test)

sub <- createSubmission(sub.prueba, "prueba") # 0.90045 ??????????
```


```{r}
## SUBIDA 2
# Igual que antes, pero remplazando NAs por la media de la columna.

set.seed(28)
sub.prueba2 <- train.predict.nas.por.media(train, test)

createSubmission(sub.prueba2, "prueba2")
```

```{r}
## SUBIDA 3
# Imputación de NAs con knn
set.seed(28)
sub.3 <- train.predict.knn.imputation(train, test)
createSubmission(sub.3, "3")
```

```{r}
## SUBIDA 4
# Imputación de NAs con knn por clases
set.seed(28)
sub.4 <- train.predict.knn.imputation.by.class(train, test)
createSubmission(sub.4, "4")
```

```{r}
## SUBIDA 5
# Imputación knn + PCA al 95 %
set.seed(28)
sub.5 <- train.predict.pca(train, test, 30)
createSubmission(sub.5, "5")
```

```{r}
## SUBIDA 6
# Imputación knn + 1-NN (prueba)
set.seed(28)
sub.6 <- train.predict.knn.imputation.k.1(train, test)
createSubmission(sub.6, "6") # 0.79 osea que no k=1
```

```{r}
## SUBIDA 7
# Imputación knn encadenada
set.seed(28)
sub.7 <- train.predict.knn.imputation.mas.precisa(train, test)
createSubmission(sub.7, "7")
```

```{r}
## SUBIDA 8
# Imputación knn + EF por consenso
set.seed(28)
sub.8 <- train.predict.knn.imputation.ef(train, test)
createSubmission(sub.8, "8")
```

```{r}
## SUBIDA 9
# Imputación knn + EF por mayoría
set.seed(28)
sub.9 <- train.predict.knn.imputation.ef.majority(train, test)
createSubmission(sub.9, "9")
```

```{r}
## SUBIDA 10
# Imputación knn + CVCF por consenso
set.seed(28)
sub.10 <- train.predict.knn.imputation.cvcf(train, test)
createSubmission(sub.10, "10")
```

```{r}
## SUBIDA 11
# Imputación knn + CVCF por mayoría (este filtro es el que parece funcionar mejor)
set.seed(28)
sub.11 <- train.predict.knn.imputation.cvcf.majority(train, test)
createSubmission(sub.11, "11")
```

```{r}
## SUBIDA 12
# Imputación knn + IPF por consenso
set.seed(28)
sub.12 <- train.predict.knn.imputation.ipf(train, test)
createSubmission(sub.12, "12")
```

```{r}
## SUBIDA 13
# Imputación knn + IPF por mayoría
set.seed(28)
sub.13 <- train.predict.knn.imputation.ipf.majority(train, test)
createSubmission(sub.13, "13")
```

```{r}
## SUBIDA 14
# 11 + simetrías
set.seed(28)
sub.14 <- train.predict.14(train, test)
createSubmission(sub.14, "14")
```

```{r}
## SUBIDA 15 
# 11 + tuneado de ks y kernels (k = 17, kernel=epanechnikov)
set.seed(28)
sub.15 <- train.predict.15(train, test, 17, "epanechnikov")
createSubmission(sub.15, "15") # 0.91168
```

```{r}
## SUBIDA 16 
# 11 + tuneado de ks y kernels (k = 17, kernel=triangular)
set.seed(28)
sub.16 <- train.predict.15(train, test, 17, "triangular")
createSubmission(sub.16, "16") # 0.91220
```

```{r}
## SUBIDA 17
# Lo mismo pero con voto mayoritario entre los mejores kernels
set.seed(28)
sub.17.rect <- train.predict.15(train, test, 17, "rectangular")
sub.17.tri  <- train.predict.15(train, test, 17, "triangular")
sub.17.epa  <- train.predict.15(train, test, 17, "epanechnikov")
sub.17.inv  <- train.predict.15(train, test, 17, "inv")
sub.17.gaus <- train.predict.15(train, test, 17, "gaussian")
sub.17.all <- data.frame(sub.17.rect, sub.17.tri, sub.17.epa, sub.17.inv, sub.17.gaus)
sub.17 <- apply(sub.17.all, 1, function(x) ifelse(sum(x==1) > 2,1,0))
createSubmission(sub.17, "17")
```

```{r}
## SUBIDA 18
# Relief + kernel gaussiano
set.seed(28)
sub.18 <- train.predict.18(train, test, 17, "gaussian")
createSubmission(sub.18, "18")

```

```{r}
## SUBIDA 19
# Relief + kernel coseno
set.seed(28)
sub.19 <- train.predict.18(train, test, 17, "cos")
createSubmission(sub.19, "19")

```

```{r}
## SUBIDA 20
# Relief + kernel coseno
set.seed(28)
sub.20 <- train.predict.18(train, test, 17, "triangular")
createSubmission(sub.20, "20")

```

```{r}
## SUBIDA 21
# 16 + PCA tuneado (20 dimensiones, gaussian)
set.seed(28)
sub.21 <- train.predict.21(train, test, 17, "gaussian", 20)
createSubmission(sub.21, "21")
```

```{r}
## SUBIDA 22
# 16 + PCA 99 %
set.seed(28)
sub.22 <- train.predict.22(train, test, 17, "gaussian", 0.99)
createSubmission(sub.22, "22")
# conclusión: PCA es basura
```

```{r}
## SUBIDA 23 (21 arreglada)
```


